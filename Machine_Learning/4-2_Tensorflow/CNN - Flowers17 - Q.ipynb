{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './dataset/Flowers17/train'\n",
    "train_bluebell_dir = os.path.join(train_dir, 'bluebell')\n",
    "train_buttercup_dir = os.path.join(train_dir, 'buttercup')\n",
    "train_coltsfoot_dir = os.path.join(train_dir, 'coltsfoot')\n",
    "train_cowslip_dir = os.path.join(train_dir, 'cowslip')\n",
    "train_crocus_dir = os.path.join(train_dir, 'crocus')\n",
    "train_daffodil_dir = os.path.join(train_dir, 'daffodil')\n",
    "train_daisy_dir = os.path.join(train_dir, 'daisy')\n",
    "train_dandelion_dir = os.path.join(train_dir, 'dandelion')\n",
    "train_fritillary_dir = os.path.join(train_dir, 'fritillary')\n",
    "train_iris_dir = os.path.join(train_dir, 'iris')\n",
    "train_lilyvalley_dir = os.path.join(train_dir, 'lilyvalley')\n",
    "train_pansy_dir = os.path.join(train_dir, 'pansy')\n",
    "train_snowdrop_dir = os.path.join(train_dir, 'snowdrop')\n",
    "train_sunflower_dir = os.path.join(train_dir, 'sunflower')\n",
    "train_tigerlily_dir = os.path.join(train_dir, 'tigerlily')\n",
    "train_tulip_dir = os.path.join(train_dir, 'tulip')\n",
    "train_windflower_dir = os.path.join(train_dir, 'windflower')\n",
    "\n",
    "test_dir = './dataset/Flowers17/test'\n",
    "test_bluebell_dir = os.path.join(test_dir, 'bluebell')\n",
    "test_buttercup_dir = os.path.join(test_dir, 'buttercup')\n",
    "test_coltsfoot_dir = os.path.join(test_dir, 'coltsfoot')\n",
    "test_cowslip_dir = os.path.join(test_dir, 'cowslip')\n",
    "test_crocus_dir = os.path.join(test_dir, 'crocus')\n",
    "test_daffodil_dir = os.path.join(test_dir, 'daffodil')\n",
    "test_daisy_dir = os.path.join(test_dir, 'daisy')\n",
    "test_dandelion_dir = os.path.join(test_dir, 'dandelion')\n",
    "test_fritillary_dir = os.path.join(test_dir, 'fritillary')\n",
    "test_iris_dir = os.path.join(test_dir, 'iris')\n",
    "test_lilyvalley_dir = os.path.join(test_dir, 'lilyvalley')\n",
    "test_pansy_dir = os.path.join(test_dir, 'pansy')\n",
    "test_snowdrop_dir = os.path.join(test_dir, 'snowdrop')\n",
    "test_sunflower_dir = os.path.join(test_dir, 'sunflower')\n",
    "test_tigerlily_dir = os.path.join(test_dir, 'tigerlily')\n",
    "test_tulip_dir = os.path.join(test_dir, 'tulip')\n",
    "test_windflower_dir = os.path.join(test_dir, 'windflower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 images belonging to 17 classes.\n",
      "Found 340 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# ImageDataGenerator 수정 가능\n",
    "######################################\n",
    "traincnt = 1020\n",
    "testcnt = 340\n",
    "batchsz = 20\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)  \n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=batchsz)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=batchsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 데이터 크기:  (20, 64, 64, 3)\n",
      "배치 레이블 크기:  (20, 17)\n",
      "[INFO] compiling model...\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 0.0632 - accuracy: 0.9265\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 0.0588 - accuracy: 0.9412\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 5s 88ms/step - loss: 0.0588 - accuracy: 0.9412\n",
      "Epoch 4/10\n",
      "11/51 [=====>........................] - ETA: 3s - loss: 0.0588 - accuracy: 0.9412"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# 추가\n",
    "######################################\n",
    "\n",
    "for d , l in train_generator:\n",
    "    print(\"배치 데이터 크기: \", d.shape)\n",
    "    print(\"배치 레이블 크기: \", l.shape)\n",
    "    break\n",
    "\n",
    "# initialize the optimizer and model\n",
    "epoch_param = 10\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    tf.keras.layers.Conv2D(input_shape=(64,64,3), kernel_size=(3,3),filters=32),\n",
    "    \n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "                        \n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),filters=64),\n",
    "                              \n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "                              \n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),filters=128),                          \n",
    "                              \n",
    "    tf.keras.layers.Flatten(),\n",
    "                              \n",
    "    tf.keras.layers.Dense(units=128,activation=\"relu\"),\n",
    "                              \n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(units=1,activation=\"sigmoid\")]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[\"accuracy\"] )\n",
    "history = model.fit(train_generator, steps_per_epoch=(traincnt//batchsz), epochs=epoch_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05882352218031883, 0.9411763548851013]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
